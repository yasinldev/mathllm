#!/bin/bash
set -e
echo "MATHLLM Performance Sprint - Quick Commands"
echo "==========================================="
echo ""
echo "SETUP"
echo "  bash setup.sh"
echo ""
echo "START SERVERS"
echo "  ./start_student.sh              # Student on port 8009"
echo "  TALKER_MODE=vllm ./start_talker.sh       # Talker vLLM on port 8010"
echo "  TALKER_MODE=llamacpp ./start_talker.sh   # Talker llama.cpp on port 8010"
echo ""
echo "HEALTHCHECK"
echo "  python3 healthcheck.py http://localhost:8009/v1  # Student"
echo "  python3 healthcheck.py http://localhost:8010/v1  # Talker"
echo ""
echo "RUN PHASES"
echo "  python3 run_phases.py A         # Smoke test"
echo "  python3 run_phases.py B         # KV-cache tuning"
echo "  python3 run_phases.py C         # Speculative decoding"
echo "  python3 run_phases.py D         # Talker choice"
echo "  python3 run_phases.py E         # 15min telemetry"
echo "  python3 run_phases.py F         # Caching test"
echo ""
echo "INDIVIDUAL TESTS"
echo "  python3 smoke_test.py"
echo "  python3 benchmark.py smoke http://localhost:8009/v1"
echo "  python3 benchmark.py load http://localhost:8009/v1"
echo ""
echo "LOGS"
echo "  tail -f /tmp/mathllm_telemetry.jsonl"
echo ""
echo "CONFIGURATION"
echo "  nano .env                       # Edit environment variables"
echo "  cat SPRINT_STATUS.txt           # View sprint status"
echo "  cat perf.md                     # View report template"
echo ""
